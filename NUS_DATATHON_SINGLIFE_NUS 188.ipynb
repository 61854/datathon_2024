{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipykernel\n",
    "%pip install pandas \n",
    "%pip install numpy\n",
    "%pip install pyarrow\n",
    "%pip install fastparquet\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install imbalanced-learn\n",
    "%pip install xgboost\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file\n",
    "filepath = \"./data/catB_train.parquet\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clntnum</th>\n",
       "      <th>race_desc</th>\n",
       "      <th>ctrycode_desc</th>\n",
       "      <th>clttype</th>\n",
       "      <th>stat_flag</th>\n",
       "      <th>min_occ_date</th>\n",
       "      <th>cltdob_fix</th>\n",
       "      <th>cltsex_fix</th>\n",
       "      <th>flg_substandard</th>\n",
       "      <th>flg_is_borderline_standard</th>\n",
       "      <th>...</th>\n",
       "      <th>recency_giclaim</th>\n",
       "      <th>giclaim_cnt_success</th>\n",
       "      <th>recency_giclaim_success</th>\n",
       "      <th>giclaim_cnt_unsuccess</th>\n",
       "      <th>recency_giclaim_unsuccess</th>\n",
       "      <th>flg_gi_claim_29d435_ever</th>\n",
       "      <th>flg_gi_claim_058815_ever</th>\n",
       "      <th>flg_gi_claim_42e115_ever</th>\n",
       "      <th>flg_gi_claim_856320_ever</th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>91b546e924</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>1974-05-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>896bae548c</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>1979-11-11</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>f364439ae6</td>\n",
       "      <td>Others</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>1976-01-28</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>70f319cfe1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>1976-03-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>2647a81328</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>1995-07-31</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          clntnum race_desc ctrycode_desc clttype stat_flag min_occ_date  \\\n",
       "19550  91b546e924   Chinese     Singapore       P    ACTIVE   2017-10-31   \n",
       "4600   896bae548c   Chinese     Singapore       P    ACTIVE   2007-05-23   \n",
       "13337  f364439ae6    Others     Singapore       P    ACTIVE   2019-08-31   \n",
       "15074  70f319cfe1   Chinese     Singapore       P    ACTIVE   2021-10-18   \n",
       "19724  2647a81328   Chinese     Singapore       P    ACTIVE   2018-07-20   \n",
       "\n",
       "       cltdob_fix cltsex_fix  flg_substandard  flg_is_borderline_standard  \\\n",
       "19550  1974-05-09     Female              0.0                         0.0   \n",
       "4600   1979-11-11       Male              0.0                         0.0   \n",
       "13337  1976-01-28       Male              0.0                         0.0   \n",
       "15074  1976-03-19     Female              0.0                         0.0   \n",
       "19724  1995-07-31     Female              0.0                         0.0   \n",
       "\n",
       "       ...  recency_giclaim  giclaim_cnt_success  recency_giclaim_success  \\\n",
       "19550  ...              NaN                 None                     None   \n",
       "4600   ...              NaN                 None                     None   \n",
       "13337  ...              NaN                 None                     None   \n",
       "15074  ...              NaN                 None                     None   \n",
       "19724  ...              NaN                 None                     None   \n",
       "\n",
       "       giclaim_cnt_unsuccess  recency_giclaim_unsuccess  \\\n",
       "19550                   None                       None   \n",
       "4600                    None                       None   \n",
       "13337                   None                       None   \n",
       "15074                   None                       None   \n",
       "19724                   None                       None   \n",
       "\n",
       "       flg_gi_claim_29d435_ever  flg_gi_claim_058815_ever  \\\n",
       "19550                      None                      None   \n",
       "4600                       None                      None   \n",
       "13337                      None                      None   \n",
       "15074                      None                      None   \n",
       "19724                      None                      None   \n",
       "\n",
       "       flg_gi_claim_42e115_ever  flg_gi_claim_856320_ever  f_purchase_lh  \n",
       "19550                      None                      None            NaN  \n",
       "4600                       None                      None            NaN  \n",
       "13337                      None                      None            NaN  \n",
       "15074                      None                      None            NaN  \n",
       "19724                      None                      None            NaN  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17992\n",
      "Number of columns: 304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns with Only One Unique Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17992\n",
      "Number of columns: 247\n"
     ]
    }
   ],
   "source": [
    "def drop_cols_with_one_value(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop columns from a DataFrame that contain only a single unique value.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with columns containing only a single unique value removed.\n",
    "    \"\"\"\n",
    "    # Identify columns with a single unique value\n",
    "    single_value_columns = [col for col in df.columns if df[col].nunique(dropna=False) == 1]\n",
    "    columns_to_drop = set(single_value_columns)\n",
    "    \n",
    "    # Drop identified columns\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = drop_cols_with_one_value(df)\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling NaN Values in Coluns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_desc</th>\n",
       "      <th>ctrycode_desc</th>\n",
       "      <th>clttype</th>\n",
       "      <th>stat_flag</th>\n",
       "      <th>min_occ_date</th>\n",
       "      <th>cltdob_fix</th>\n",
       "      <th>cltsex_fix</th>\n",
       "      <th>flg_substandard</th>\n",
       "      <th>flg_is_borderline_standard</th>\n",
       "      <th>flg_is_revised_term</th>\n",
       "      <th>...</th>\n",
       "      <th>n_months_last_bought_grp_fe5fb8</th>\n",
       "      <th>n_months_last_bought_grp_94baec</th>\n",
       "      <th>n_months_last_bought_grp_e91421</th>\n",
       "      <th>n_months_last_bought_lh_f852af</th>\n",
       "      <th>n_months_last_bought_lh_947b15</th>\n",
       "      <th>n_months_last_bought_32c74c</th>\n",
       "      <th>f_elx</th>\n",
       "      <th>f_mindef_mha</th>\n",
       "      <th>f_retail</th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2017</td>\n",
       "      <td>1974</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2007</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>Others</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2019</td>\n",
       "      <td>1976</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2021</td>\n",
       "      <td>1976</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1995</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race_desc ctrycode_desc clttype stat_flag min_occ_date cltdob_fix  \\\n",
       "19550   Chinese     Singapore       P    ACTIVE         2017       1974   \n",
       "4600    Chinese     Singapore       P    ACTIVE         2007       1979   \n",
       "13337    Others     Singapore       P    ACTIVE         2019       1976   \n",
       "15074   Chinese     Singapore       P    ACTIVE         2021       1976   \n",
       "19724   Chinese     Singapore       P    ACTIVE         2018       1995   \n",
       "\n",
       "      cltsex_fix  flg_substandard  flg_is_borderline_standard  \\\n",
       "19550     Female              0.0                         0.0   \n",
       "4600        Male              0.0                         0.0   \n",
       "13337       Male              0.0                         0.0   \n",
       "15074     Female              0.0                         0.0   \n",
       "19724     Female              0.0                         0.0   \n",
       "\n",
       "       flg_is_revised_term  ...  n_months_last_bought_grp_fe5fb8  \\\n",
       "19550                  0.0  ...                             9999   \n",
       "4600                   0.0  ...                             9999   \n",
       "13337                  0.0  ...                             9999   \n",
       "15074                  0.0  ...                             9999   \n",
       "19724                  0.0  ...                             9999   \n",
       "\n",
       "       n_months_last_bought_grp_94baec  n_months_last_bought_grp_e91421  \\\n",
       "19550                             9999                             9999   \n",
       "4600                              9999                             9999   \n",
       "13337                             9999                             9999   \n",
       "15074                             9999                             9999   \n",
       "19724                             9999                             9999   \n",
       "\n",
       "       n_months_last_bought_lh_f852af  n_months_last_bought_lh_947b15  \\\n",
       "19550                            9999                            9999   \n",
       "4600                             9999                            9999   \n",
       "13337                            9999                            9999   \n",
       "15074                            9999                            9999   \n",
       "19724                            9999                            9999   \n",
       "\n",
       "       n_months_last_bought_32c74c  f_elx  f_mindef_mha  f_retail  \\\n",
       "19550                         9999      0             0         1   \n",
       "4600                          9999      0             0         1   \n",
       "13337                         9999      0             0         1   \n",
       "15074                         9999      0             0         1   \n",
       "19724                         9999      0             0         1   \n",
       "\n",
       "       f_purchase_lh  \n",
       "19550            0.0  \n",
       "4600             0.0  \n",
       "13337            0.0  \n",
       "15074            0.0  \n",
       "19724            0.0  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_na(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values in a DataFrame through a series of data imputation and preprocessing steps.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with missing values handled.\n",
    "    \"\"\"\n",
    "    # Convert target col to 0 or 1\n",
    "    df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
    "\n",
    "    # Dropping columns where na values take up 65% of the column\n",
    "    df_temp = df.dropna(thresh = df.shape[0]*0.2, axis = 1).copy()\n",
    "    df_temp = df_temp.drop(['clntnum'], axis=1)\n",
    "\n",
    "    # Try casting categorical columns to numeric to reduce encoding\n",
    "    non_numeric_cols = df_temp.select_dtypes(include=[\"object\"]).columns\n",
    "    for i in range(len(non_numeric_cols)):\n",
    "        try:\n",
    "            df_temp[non_numeric_cols[i]] = pd.to_numeric(df_temp[non_numeric_cols[i]])\n",
    "        except ValueError:\n",
    "            continue\n",
    "    non_numeric_cols = df_temp.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    # Extract year from columns containing dates\n",
    "    df_temp['cltdob_fix'] = df_temp['cltdob_fix'].str[:4]\n",
    "    df_temp['min_occ_date'] = df_temp['min_occ_date'].str[:4]\n",
    "\n",
    "    # Fill NA values for categorical columns with 'Missing'\n",
    "    df_temp[non_numeric_cols] = df_temp[non_numeric_cols].fillna('Missing')\n",
    "\n",
    "    # Fill NA values for numerical columns with mean. For binary columns, mode is used\n",
    "    numeric_cols_with_na = df_temp.select_dtypes(include=[\"int64\", \"float64\"]).columns[df_temp.select_dtypes(include=[\"int64\", \"float64\"]).isna().any()].tolist()\n",
    "    \n",
    "    for i in numeric_cols_with_na:\n",
    "        if len(df_temp[i].unique()) <= 3:\n",
    "            df_temp[i] = df_temp[i].fillna(df_temp[i].mode()[0])\n",
    "        else:\n",
    "            df_temp[i] = df_temp[i].fillna(df_temp[i].mean())\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "test_df = handle_na(df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes strings found in a dataframe into numbers using sklearn's LabelEncoder\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with numerical values.\n",
    "    \"\"\"        \n",
    "    # race and ctrycode is manually encoded into binary\n",
    "    test_df['race_desc'] = np.where(test_df['race_desc'] == 'Chinese', 1, 0)\n",
    "    test_df['ctrycode_desc'] = np.where(test_df['ctrycode_desc'] == 'Singapore', 1, 0)\n",
    "\n",
    "    # Dataframe manipulation via LabelEncoder\n",
    "    for column in df.columns:\n",
    "        # if column is already in numbers, skip the column\n",
    "        if df[column].dtype == np.number:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column])\n",
    "\n",
    "    return df\n",
    "\n",
    "encoded_df = encoder(test_df)\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split and Resampling Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_resample(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits a dataframe into training and test sets, and oversamples the training set via SMOTE.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - (x_train_resampled, x_test, y_train_resampled, y_test) (tuple of np.ndarray): 4 arrays attained after splitting the dataset into training and test sets.\n",
    "    \"\"\"      \n",
    "\n",
    "    # split into x and y dataframes\n",
    "    x = df.drop(['f_purchase_lh'], axis=1)\n",
    "    y = df['f_purchase_lh']\n",
    "\n",
    "    # MinMax normalization of values in x\n",
    "    churn_scaler = MinMaxScaler()\n",
    "    churn_scaler.fit(x)\n",
    "    x = churn_scaler.transform(x)\n",
    "\n",
    "    # split dataset into train and test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # rebalance dataset using smote\n",
    "    sm = SMOTE(random_state=1, k_neighbors=20)\n",
    "    x_train_resampled, y_train_resampled = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "    return x_train_resampled, x_test, y_train_resampled, y_test\n",
    "\n",
    "x_train_resampled, x_test, y_train_resampled, y_test = train_test_resample(encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      3457\n",
      "         1.0       0.28      0.31      0.29       142\n",
      "\n",
      "    accuracy                           0.94      3599\n",
      "   macro avg       0.63      0.64      0.63      3599\n",
      "weighted avg       0.94      0.94      0.94      3599\n",
      "\n",
      "[[3343  114]\n",
      " [  98   44]]\n"
     ]
    }
   ],
   "source": [
    "def prediction(x_train_resampled, x_test, y_train_resampled, y_test) -> tuple:\n",
    "      \"\"\"\n",
    "      Predicts whether a customer will purchase a policy in the next 3 months.\n",
    "\n",
    "      Parameters:\n",
    "      - x_train_resampled (np.ndarray): Resampled training set for features\n",
    "      - x_test (np.ndarray): Test set for features\n",
    "      - y_train_resampled (np.ndarray): Resampled training set for target column\n",
    "      - y_test (np.ndarray): Test set for target column\n",
    "\n",
    "      Returns:\n",
    "      - (y_pred, class_report, con_matrix) (tuple): \n",
    "        1) y_pred is the prediction of target column (either 0 or 1)\n",
    "        2) class_report contains the various scores (accuracy, f1-score etc) of the model\n",
    "        3) con_matrix contains the TP, TN, FP, FN values\n",
    "      \"\"\"     \n",
    "\n",
    "      # xgboost model\n",
    "      xgb_model = XGBClassifier(\n",
    "            learning_rate = 0.01,\n",
    "            subsample = 0.1,\n",
    "            colsample_bytree = 0.1,\n",
    "            max_depth = 8,\n",
    "      )\n",
    "\n",
    "      xgb_model.fit(x_train_resampled, y_train_resampled)\n",
    "      y_pred = xgb_model.predict(x_test)\n",
    "      class_report = classification_report(y_test, y_pred)\n",
    "      con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "      return y_pred, class_report, con_matrix\n",
    "\n",
    "y_pred, class_report, con_matrix = prediction(x_train_resampled, x_test, y_train_resampled, y_test)\n",
    "print(y_pred)\n",
    "print(class_report)\n",
    "print(con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "    The function accepts a dataframe as input and return an iterable (list)\n",
    "    of binary classes as output.\n",
    "\n",
    "    The function should be coded to test on hidden data\n",
    "    and should include any preprocessing functions needed for your model to perform. \n",
    "        \n",
    "    All relevant code MUST be included in this function.\n",
    "    '''\n",
    "    result = []\n",
    "\n",
    "    # drop columns with only one unique value \n",
    "    df = drop_cols_with_one_value(hidden_data)\n",
    "\n",
    "    # replace na in columns\n",
    "    cleaned_df = handle_na(df)\n",
    "\n",
    "    # encode dataframe into numbers\n",
    "    encoded_df = encoder(cleaned_df)\n",
    "\n",
    "    # train test split and resample the training set\n",
    "    x_train_resampled, x_test, y_train_resampled, y_test = train_test_resample(encoded_df)\n",
    "\n",
    "    # generate the predictions\n",
    "    result, class_report, con_matrix = prediction(x_train_resampled, x_test, y_train_resampled, y_test)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
