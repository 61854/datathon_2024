{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (6.29.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (8.20.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipykernel) (5.14.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.1.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (306)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pyarrow) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2023.10.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from fastparquet) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from fastparquet) (1.26.3)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.8.1-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting fsspec (from fastparquet)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from fastparquet) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2023.10.1-cp311-cp311-win_amd64.whl (667 kB)\n",
      "   ---------------------------------------- 0.0/667.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 667.9/667.9 kB 21.2 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.8.1-cp311-none-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 33.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "   ---------------------------------------- 0.0/169.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 169.0/169.0 kB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\n",
      "Successfully installed cramjam-2.8.1 fastparquet-2023.10.1 fsspec-2023.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from imbalanced-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\desktop\\datathon 2024 and stuff\\datathon_2024\\.venv\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipykernel\n",
    "%pip install pandas \n",
    "%pip install numpy\n",
    "%pip install pyarrow\n",
    "%pip install fastparquet\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install imbalanced-learn\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file\n",
    "filepath = \"./data/catB_train.parquet\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clntnum`: Unique identifier for the client.\n",
    "\n",
    "`race_desc`: Description of the client's race.\n",
    "\n",
    "`ctrycode_desc`: Country code indicating the client's location.\n",
    "\n",
    "`clttype`: Customer status.\n",
    "\n",
    "`stat_flag`: Flag indicating ACTIVE, LAPSED or MATURED. E.g. if there’s at least one inforce policy, then the flag would be ACTIVE. If all of the client’s policies are all lapsed, then it is LAPSED.\n",
    "\n",
    "`min_occ_date`: Date of the client's first interaction or policy purchase with the company.\n",
    "\n",
    "`cltdob_fix`: Fixed or corrected date of birth of the client.\n",
    "\n",
    "`cltsex_fix`: Fixed or corrected gender of the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clntnum</th>\n",
       "      <th>race_desc</th>\n",
       "      <th>ctrycode_desc</th>\n",
       "      <th>clttype</th>\n",
       "      <th>stat_flag</th>\n",
       "      <th>min_occ_date</th>\n",
       "      <th>cltdob_fix</th>\n",
       "      <th>cltsex_fix</th>\n",
       "      <th>flg_substandard</th>\n",
       "      <th>flg_is_borderline_standard</th>\n",
       "      <th>...</th>\n",
       "      <th>recency_hlthclaim_success</th>\n",
       "      <th>hlthclaim_cnt_unsuccess</th>\n",
       "      <th>recency_hlthclaim_unsuccess</th>\n",
       "      <th>flg_hlthclaim_839f8a_ever</th>\n",
       "      <th>recency_hlthclaim_839f8a</th>\n",
       "      <th>flg_hlthclaim_14cb37_ever</th>\n",
       "      <th>recency_hlthclaim_14cb37</th>\n",
       "      <th>giclaim_amt</th>\n",
       "      <th>recency_giclaim</th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>91b546e924</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>1974-05-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>896bae548c</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>1979-11-11</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>f364439ae6</td>\n",
       "      <td>Others</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>1976-01-28</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15074</th>\n",
       "      <td>70f319cfe1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>1976-03-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19724</th>\n",
       "      <td>2647a81328</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>P</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>1995-07-31</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          clntnum race_desc ctrycode_desc clttype stat_flag min_occ_date  \\\n",
       "19550  91b546e924   Chinese     Singapore       P    ACTIVE   2017-10-31   \n",
       "4600   896bae548c   Chinese     Singapore       P    ACTIVE   2007-05-23   \n",
       "13337  f364439ae6    Others     Singapore       P    ACTIVE   2019-08-31   \n",
       "15074  70f319cfe1   Chinese     Singapore       P    ACTIVE   2021-10-18   \n",
       "19724  2647a81328   Chinese     Singapore       P    ACTIVE   2018-07-20   \n",
       "\n",
       "       cltdob_fix cltsex_fix  flg_substandard  flg_is_borderline_standard  \\\n",
       "19550  1974-05-09     Female              0.0                         0.0   \n",
       "4600   1979-11-11       Male              0.0                         0.0   \n",
       "13337  1976-01-28       Male              0.0                         0.0   \n",
       "15074  1976-03-19     Female              0.0                         0.0   \n",
       "19724  1995-07-31     Female              0.0                         0.0   \n",
       "\n",
       "       ...  recency_hlthclaim_success  hlthclaim_cnt_unsuccess  \\\n",
       "19550  ...                        NaN                      NaN   \n",
       "4600   ...                        NaN                      NaN   \n",
       "13337  ...                        NaN                      NaN   \n",
       "15074  ...                        NaN                      NaN   \n",
       "19724  ...                        NaN                      NaN   \n",
       "\n",
       "       recency_hlthclaim_unsuccess  flg_hlthclaim_839f8a_ever  \\\n",
       "19550                          NaN                        NaN   \n",
       "4600                           NaN                        NaN   \n",
       "13337                          NaN                        NaN   \n",
       "15074                          NaN                        NaN   \n",
       "19724                          NaN                        NaN   \n",
       "\n",
       "       recency_hlthclaim_839f8a  flg_hlthclaim_14cb37_ever  \\\n",
       "19550                       NaN                        NaN   \n",
       "4600                        NaN                        NaN   \n",
       "13337                       NaN                        NaN   \n",
       "15074                       NaN                        NaN   \n",
       "19724                       NaN                        NaN   \n",
       "\n",
       "       recency_hlthclaim_14cb37  giclaim_amt  recency_giclaim  f_purchase_lh  \n",
       "19550                       NaN         None              NaN            NaN  \n",
       "4600                        NaN         None              NaN            NaN  \n",
       "13337                       NaN         None              NaN            NaN  \n",
       "15074                       NaN         None              NaN            NaN  \n",
       "19724                       NaN         None              NaN            NaN  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###...code...###\n",
    "test_df = pd.read_parquet(filepath)\n",
    "\n",
    "# drop these columns\n",
    "to_drop = []\n",
    "for i in range(len(test_df.columns)):\n",
    "    # if column has only 1 unique value, that column is unimportant as a feature\n",
    "    if len(test_df[test_df.columns[i]].unique()) == 1:\n",
    "        #print(len(test_df[test_df.columns[i]].unique()))\n",
    "        to_drop.append(i)\n",
    "\n",
    "dropped_df = test_df.drop(test_df.columns[to_drop], axis=1)\n",
    "dropped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_desc\n",
      "Chinese    10520\n",
      "Indian       849\n",
      "Malay        928\n",
      "Others      1699\n",
      "Name: clntnum, dtype: int64\n",
      "\n",
      "           f_purchase_lh\n",
      "race_desc               \n",
      "Chinese              521\n",
      "Indian                11\n",
      "Malay                 21\n",
      "Others               112\n",
      "\n",
      "Chinese: 4.952471482889734\n",
      "Indian: 1.2956419316843346\n",
      "Malay: 2.2629310344827585\n",
      "Others: 6.59211300765156\n"
     ]
    }
   ],
   "source": [
    "# By Race\n",
    "print(dropped_df.groupby('race_desc').count()['clntnum'])\n",
    "print()\n",
    "\n",
    "print(dropped_df.groupby('race_desc').agg({\"f_purchase_lh\": 'count'}))\n",
    "print()\n",
    "\n",
    "print(f'Chinese: {521/10520*100}')\n",
    "print(f'Indian: {11/849 *100}')\n",
    "print(f'Malay: {21/928 *100}')\n",
    "print(f'Others: {112/1699 *100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrycode_desc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia-Herzegovina</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f_purchase_lh\n",
       "ctrycode_desc                    \n",
       "Singapore                     710\n",
       "Australia                       0\n",
       "Bosnia-Herzegovina              0\n",
       "United States                   0\n",
       "United Kingdom                  0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By country\n",
    "# only singaporeans are likely to buy insurance\n",
    "dropped_df.groupby('ctrycode_desc').agg({\"f_purchase_lh\": 'count'}).sort_values(by='f_purchase_lh', ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clttype\n",
      "C       24\n",
      "G     3311\n",
      "P    14657\n",
      "Name: clntnum, dtype: int64\n",
      "\n",
      "         f_purchase_lh\n",
      "clttype               \n",
      "C                    2\n",
      "G                   36\n",
      "P                  672\n",
      "\n",
      "C type: 8.333333333333332\n",
      "G type: 1.0872848082150408\n",
      "P type: 4.584840008187214\n"
     ]
    }
   ],
   "source": [
    "# By clttype\n",
    "print(dropped_df.groupby('clttype').count()['clntnum'])\n",
    "print()\n",
    "\n",
    "print(dropped_df.groupby('clttype').agg({\"f_purchase_lh\": 'count'}))\n",
    "print()\n",
    "\n",
    "print(f'C type: {2/24*100}')\n",
    "print(f'G type: {36/3311 *100}')\n",
    "print(f'P type: {672/14657 *100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_flag\n",
      "ACTIVE     17205\n",
      "LAPSED       775\n",
      "MATURED       12\n",
      "Name: clntnum, dtype: int64\n",
      "\n",
      "           f_purchase_lh\n",
      "stat_flag               \n",
      "ACTIVE               694\n",
      "LAPSED                16\n",
      "MATURED                0\n",
      "\n",
      "Active: 4.033711130485324\n",
      "Lapsed: 2.064516129032258\n"
     ]
    }
   ],
   "source": [
    "# By stat_flag\n",
    "print(dropped_df.groupby('stat_flag').count()['clntnum'])\n",
    "print()\n",
    "\n",
    "print(dropped_df.groupby('stat_flag').agg({\"f_purchase_lh\": 'count'}))\n",
    "print()\n",
    "\n",
    "print(f'Active: {694/17205 *100}')\n",
    "print(f'Lapsed: {16/775 *100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_occ_year\n",
      "1954       1\n",
      "1959       1\n",
      "1962       1\n",
      "1968       1\n",
      "1971       1\n",
      "1972       2\n",
      "1974       4\n",
      "1975       2\n",
      "1977       4\n",
      "1978       1\n",
      "1979       5\n",
      "1980       3\n",
      "1981       1\n",
      "1982       4\n",
      "1983      13\n",
      "1984       6\n",
      "1985       8\n",
      "1986      12\n",
      "1987      12\n",
      "1988      31\n",
      "1989      24\n",
      "1990      37\n",
      "1991      46\n",
      "1992      38\n",
      "1993      38\n",
      "1994      44\n",
      "1995      42\n",
      "1996      41\n",
      "1997      29\n",
      "1998      46\n",
      "1999      25\n",
      "2000      54\n",
      "2001      98\n",
      "2002     168\n",
      "2003     218\n",
      "2004     247\n",
      "2005     407\n",
      "2006     486\n",
      "2007     394\n",
      "2008     634\n",
      "2009     597\n",
      "2010     665\n",
      "2011     739\n",
      "2012     715\n",
      "2013     721\n",
      "2014     787\n",
      "2015    1109\n",
      "2016    1149\n",
      "2017     803\n",
      "2018     948\n",
      "2019     898\n",
      "2020    1301\n",
      "2021     864\n",
      "2022    1442\n",
      "2023    2015\n",
      "None      10\n",
      "Name: clntnum, dtype: int64\n",
      "\n",
      "              f_purchase_lh\n",
      "min_occ_year               \n",
      "1954                      0\n",
      "1959                      0\n",
      "1962                      0\n",
      "1968                      0\n",
      "1971                      0\n",
      "1972                      0\n",
      "1974                      0\n",
      "1975                      0\n",
      "1977                      0\n",
      "1978                      0\n",
      "1979                      0\n",
      "1980                      1\n",
      "1981                      0\n",
      "1982                      0\n",
      "1983                      1\n",
      "1984                      0\n",
      "1985                      0\n",
      "1986                      0\n",
      "1987                      0\n",
      "1988                      2\n",
      "1989                      1\n",
      "1990                      1\n",
      "1991                      5\n",
      "1992                      4\n",
      "1993                      1\n",
      "1994                      3\n",
      "1995                      2\n",
      "1996                      3\n",
      "1997                      0\n",
      "1998                      4\n",
      "1999                      2\n",
      "2000                      2\n",
      "2001                      6\n",
      "2002                      8\n",
      "2003                      8\n",
      "2004                     18\n",
      "2005                     17\n",
      "2006                     22\n",
      "2007                     16\n",
      "2008                     20\n",
      "2009                     35\n",
      "2010                     28\n",
      "2011                     41\n",
      "2012                     26\n",
      "2013                     36\n",
      "2014                     28\n",
      "2015                     46\n",
      "2016                     48\n",
      "2017                     32\n",
      "2018                     38\n",
      "2019                     36\n",
      "2020                     46\n",
      "2021                     36\n",
      "2022                     46\n",
      "2023                     41\n",
      "None                      0\n"
     ]
    }
   ],
   "source": [
    "# by min_occ_year\n",
    "new_df = dropped_df\n",
    "new_df['min_occ_year'] = dropped_df['min_occ_date'].str.slice(stop=4) \n",
    "\n",
    "print(new_df.groupby('min_occ_year').count()['clntnum'])\n",
    "print()\n",
    "\n",
    "print(new_df.groupby('min_occ_year').agg({\"f_purchase_lh\": 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_purchase_lh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cltdob_fix_year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f_purchase_lh\n",
       "cltdob_fix_year               \n",
       "1990                        40\n",
       "1989                        36\n",
       "1993                        30\n",
       "1991                        30\n",
       "1983                        25\n",
       "...                        ...\n",
       "1945                         0\n",
       "1946                         0\n",
       "1947                         0\n",
       "1949                         0\n",
       "1924                         0\n",
       "\n",
       "[83 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by cltdob_fix\n",
    "new_df['cltdob_fix_year'] = dropped_df['cltdob_fix'].str.slice(stop=4) \n",
    "\n",
    "# print(new_df.groupby('cltdob_fix_year').count()['clntnum'])\n",
    "# print()\n",
    "\n",
    "new_df.groupby('cltdob_fix_year').agg({\"f_purchase_lh\": 'count'}).sort_values('f_purchase_lh', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cltsex_fix\n",
      "Female    8196\n",
      "Male      9773\n",
      "Name: clntnum, dtype: int64\n",
      "\n",
      "            f_purchase_lh\n",
      "cltsex_fix               \n",
      "Female                345\n",
      "Male                  363\n",
      "\n",
      "Female: 4.209370424597365\n",
      "Male: 3.714314949350251\n"
     ]
    }
   ],
   "source": [
    "# By Gender\n",
    "print(dropped_df.groupby('cltsex_fix').count()['clntnum'])\n",
    "print()\n",
    "\n",
    "print(dropped_df.groupby('cltsex_fix').agg({\"f_purchase_lh\": 'count'}))\n",
    "print()\n",
    "\n",
    "print(f'Female: {345/8196 *100}')\n",
    "print(f'Male: {363/9773 *100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of target column')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check if dataset is imbalanced\n",
    "dropped_df[\"f_purchase_lh\"] = dropped_df[\"f_purchase_lh\"].fillna(0)\n",
    "\n",
    "plt.bar(x = ('0','1'),\n",
    "        height = ((dropped_df['f_purchase_lh']==0).sum(),\n",
    "                  (dropped_df['f_purchase_lh']==1).sum()))\n",
    "plt.title('Distribution of target column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_na(df):\n",
    "    # Dropping columns where na values take up 65% of the column\n",
    "    df_temp = dropped_df.dropna(thresh = dropped_df.shape[0]*0.35, axis = 1).copy()\n",
    "\n",
    "    # Try casting categorical columns to numeric to reduce encoding\n",
    "    non_numeric_cols = df_temp.select_dtypes(include=[\"object\"]).columns\n",
    "    for i in range(len(non_numeric_cols)):\n",
    "        try:\n",
    "            df_temp[non_numeric_cols[i]] = pd.to_numeric(df_temp[non_numeric_cols[i]])\n",
    "        except ValueError:\n",
    "            continue\n",
    "    non_numeric_cols = df_temp.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    # Extract year from columns containing dates\n",
    "    df_temp['cltdob_fix'] = df_temp['cltdob_fix'].str[:4]\n",
    "    df_temp['min_occ_date'] = df_temp['min_occ_date'].str[:4]\n",
    "\n",
    "    # Fill NA values for categorical columns with 'Missing'\n",
    "    df_temp[non_numeric_cols] = df_temp[non_numeric_cols].fillna('Missing')\n",
    "\n",
    "    # Fill NA values for numerical columns with mean. For binary columns, mode is used\n",
    "    numeric_cols_with_na = df_temp.select_dtypes(include=[\"int64\", \"float64\"]).columns[df_temp.select_dtypes(include=[\"int64\", \"float64\"]).isna().any()].tolist()\n",
    "    \n",
    "    for i in numeric_cols_with_na:\n",
    "        if len(df_temp[i].unique()) <= 3:\n",
    "            df_temp[i] = df_temp[i].fillna(df_temp[i].mode()[0])\n",
    "        else:\n",
    "            df_temp[i] = df_temp[i].fillna(df_temp[i].mean())\n",
    "    return df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = handle_na(dropped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17992, 355)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "#clntnum is dropped since it is only a unique identifier\n",
    "X = df_temp.drop(['f_purchase_lh','clntnum'], axis=1)\n",
    "y = df_temp['f_purchase_lh']\n",
    "\n",
    "non_numeric_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "oh_encoder = OneHotEncoder()\n",
    "transformer = make_column_transformer((oh_encoder, non_numeric_cols), remainder = 'passthrough')\n",
    "encoded_df = pd.DataFrame(transformer.fit_transform(X))\n",
    "\n",
    "print(encoded_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of target column (training)\n",
      "0: 12087\n",
      "1: 507\n",
      "Distribution of target column after oversampling (training)\n",
      "0: 12087\n",
      "1: 12087\n"
     ]
    }
   ],
   "source": [
    "print('Count of target column (training)')\n",
    "print(f'0: {(y_train==0).sum()}\\n1: {(y_train==1).sum()}')\n",
    "\n",
    "print('Distribution of target column after oversampling (training)')\n",
    "print(f'0: {(y_train_ros==0).sum()}\\n1: {(y_train_ros==1).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state = 0)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4752  443]\n",
      " [ 122   81]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.91      0.94      5195\n",
      "         1.0       0.15      0.40      0.22       203\n",
      "\n",
      "    accuracy                           0.90      5398\n",
      "   macro avg       0.56      0.66      0.58      5398\n",
      "weighted avg       0.94      0.90      0.92      5398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "dt_ros = DecisionTreeClassifier(max_depth = 5, random_state=0)\n",
    "dt_ros.fit(X_train_ros, y_train_ros)\n",
    "y_pred = dt_ros.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4961  234]\n",
      " [ 134   69]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96      5195\n",
      "         1.0       0.23      0.34      0.27       203\n",
      "\n",
      "    accuracy                           0.93      5398\n",
      "   macro avg       0.60      0.65      0.62      5398\n",
      "weighted avg       0.95      0.93      0.94      5398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "dt_adasyn = DecisionTreeClassifier(max_depth = 8, random_state=0)\n",
    "dt_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "y_pred = dt_adasyn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RFECV\n\u001b[0;32m      3\u001b[0m rfecv \u001b[38;5;241m=\u001b[39m RFECV(estimator \u001b[38;5;241m=\u001b[39m dt_adasyn, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_train_rfecv \u001b[38;5;241m=\u001b[39m \u001b[43mrfecv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_adasyn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_adasyn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Number of features to select based on cross-validation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m num_features_selected \u001b[38;5;241m=\u001b[39m rfecv\u001b[38;5;241m.\u001b[39mn_features_\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:768\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;66;03m# Re-execute an elimination with best_k over the whole set\u001b[39;00m\n\u001b[0;32m    760\u001b[0m rfe \u001b[38;5;241m=\u001b[39m RFE(\n\u001b[0;32m    761\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator,\n\u001b[0;32m    762\u001b[0m     n_features_to_select\u001b[38;5;241m=\u001b[39mn_features_to_select,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    766\u001b[0m )\n\u001b[1;32m--> 768\u001b[0m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# Set final attributes\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_ \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39msupport_\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:258\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:305\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 305\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    308\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    309\u001b[0m     estimator,\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    311\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    312\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Datathon 2024 and stuff\\datathon_2024\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(estimator = dt_adasyn, cv = 5, scoring='f1')\n",
    "X_train_rfecv = rfecv.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Number of features to select based on cross-validation\n",
    "num_features_selected = rfecv.n_features_\n",
    "print(\"Number of features selected:\", num_features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96      5195\n",
      "         1.0       0.21      0.37      0.27       203\n",
      "\n",
      "    accuracy                           0.92      5398\n",
      "   macro avg       0.59      0.66      0.61      5398\n",
      "weighted avg       0.95      0.92      0.93      5398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfecv.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
